# Yang Zhan ğŸ‘‹

I am currently pursuing the Ph.D. degree with the **School of Artificial Intelligence, OPtics and ElectroNics** (**iOPEN**), *Northwestern Polytechnical University*, Xiâ€™an, China.

### ğŸ†My research interests
#### *Vision and Language*, *Large Language Model*, *Multimodal Machine Learning*, *AI for Remote Sensing*, and *Data Mining*.


### ğŸ’¬Projects
- ğŸš€ â€¦â€¦
- ğŸš€ **SkyEyeGPT** (**å¤©çœ¼GPT**, **SkyEye-968k**) [[Paper](https://arxiv.org/abs/2401.09712)][[Code](https://github.com/ZhanYang-nwpu/SkyEyeGPT)][[Dataset](https://huggingface.co/datasets/ZhanYang-nwpu/SkyEye-968k)]
- ğŸš€ **Mono3DVG** (**Mono3DRefer**) AAAI'24 [[AAAI Paper](https://doi.org/10.1609/aaai.v38i7.28525)][[ArXiv Paper](https://arxiv.org/abs/2312.08022)][[Code](https://github.com/ZhanYang-nwpu/Mono3DVG)][[Dataset](https://drive.google.com/drive/folders/1ICBv0SRbRIUnl_z8DVuH8lz7KQt580EI?usp=drive_link)][[AAAI Video/Poster](https://ojs.aaai.org/index.php/AAAI/article/view/28525/29024)][[Baidu Poster](https://pan.baidu.com/s/1jT3GWYWGPK2iSkP_kFDQ-A?pwd=yidy)][[Baidu PPT](https://pan.baidu.com/s/1kRszkeoeepRfpC9qTU7-Nw?pwd=ufwy)]
- ğŸš€ **PE-RSITR** (**MRS-Adapter**) T-GRS'23 [[Paper](https://ieeexplore.ieee.org/document/10231134)][[Code](https://github.com/ZhanYang-nwpu/PE-RSITR)][[Dataset](https://drive.google.com/drive/folders/1F6WBQB-1PLqABh-uDv9m-KPdChakWcWY?usp=sharing)]
- ğŸš€ **RSVG** (**DIOR-RSVG**) T-GRS'23 [[Paper](https://ieeexplore.ieee.org/document/10056343)][[Code](https://github.com/ZhanYang-nwpu/RSVG-pytorch)][[Dataset](https://drive.google.com/drive/folders/1hTqtYsC6B-m4ED2ewx5oKuYZV13EoJp_?usp=sharing)]
- ğŸš€ **STMGCN** T-ITS'22 [[Paper](https://ieeexplore.ieee.org/document/9868210)]
- ğŸš€ **MVFFNet** PRLetters'21 [[Paper](https://www.sciencedirect.com/science/article/pii/S0167865521002737)]

### ğŸ“¢News
ğŸ”¥ **[â€¦â€¦]**:

ğŸ”¥ **[2024]**: Remote sensing multimodal large language model is an ongoing project. We will be working on improving it.

ğŸ”¥ **[2024/1]**: **SkyEyeGPT** now is available at arXiv. 
- This work explores the **remote sensing multimodal large language model (vision-language)**. We meticulously curate a high-quality remote sensing multi-modal instruction tuning dataset, including single-task and multi-task conversation instructions, namely **SkyEye-968k**. We develop **SkyEyeGPT**, which unifies remote sensing vision-language tasks and breaks new ground in enabling the unified modeling of remote sensing vision and LLM.  Experiments on 8 datasets for remote sensing vision language tasks demonstrate SkyEyeGPTâ€™s superiority in image-level and region-level tasks. Specially, it has shown encouraging results in some tests, compared with GPT-4V. 

ğŸ”¥ **[2024/1]**: A curated list about [Remote Sensing Multimodal Large Language Model (Vision-Language)](https://github.com/ZhanYang-nwpu/Awesome-Remote-Sensing-Multimodal-Large-Language-Model) is created.

ğŸ”¥ **[2023/12]**: Propose theÂ **Mono3DVG** task and construct theÂ **Mono3DRefer**Â datasetï¼ˆaccepted byÂ **AAAI2024**ï¼‰!
- For intelligent systems and robots, understanding objects based on language expressions in real 3D scenes is an important capability for human-machine interaction. However, existing 2D visual grounding cannot capture the true 3D extent of the referred objects. 3D visual grounding requires laser radars or RGB-D sensors, which greatly limits its application scenarios due to the expensive cost and device limitations. Monocular 3D object detection is low-cost and has strong applicability, but it cannot localize specific objects. We introduce a novel task of **3D visual grounding in monocular RGB images** using language descriptions with appearance and geometry information. We create **Mono3DRefer**, which is the first dataset that leverages the ChatGPT to generate descriptions. We believe Mono3DVG can be widely applied since it does not require strict conditions such as RGB-D sensors, LiDARs, or industrial cameras. The application scenarios are wide, such as drones, surveillance systems, intelligent vehicles, robots, and other devices equipped with cameras.

ğŸ”¥ **[2023/08]**: Propose a novel **PE-RSITR** task and provide empirical studiesï¼ˆaccepted by **T-GRS**ï¼‰!
- This work explores the **parameter-efficient transfer learning** for remote sensing image-text retrieval. Our proposed **MRS-Adapter** reduces **98.9\%** of fine-tuned parameters and its performance exceeds traditional methods by **7\%**~**13\%**.
  
ğŸ”¥ **[2023/02]**: Propose the **RSVG** task and construct the **DIOR-RSVG** datasetï¼ˆaccepted by **T-GRS**ï¼‰!
- This work explores the **visual grounding** for remote sensing domain. The **DIOR-RSVG** takes DIOR dataset as the data source and is built using an automatic generation algorithm with manual verification. A novel transformer-based **MGVLF** model is devised to solve problems of the cluttered background and scale variation of RS images.
  
ğŸ”¥ **[2022/08]**: Propose a **STMGCN** for vessel traffic flow predictionï¼ˆaccepted by **T-ITS**ï¼‰!
- This work explores **multi-graph convolutional network** for vessel traffic flow prediction. Due to the difference between water traffic and land traffic, we propose a **big data-driven maritime traffic network extraction algorithm** to construct a "road network". We then design a **STMGCN** to make full use of maritime graphs and multi-graph learning (including distance graph, interaction graph, and correlation graph).

ğŸ”¥ **[2021/08]**: Propose a **MVFFNet** for imbalanced ship classificationï¼ˆaccepted by **PRLetters**ï¼‰!

### ğŸŒ± Academic Services 
- **Journal Reviewer**:
  - IEEE Transactions on Multimedia (T-MM)
  - IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT)
  - IEEE Transactions on Geoscience and Remote Sensing (T-GRS)
  - Neural Networks (NEUNET)
  - IEEE Geoscience and Remote Sensing Letters (IEEE GRSL)
  - Pattern Recognition Letters (PRLETTERS)
  - Journal of Supercomputing (J SUPERCOMPUT)
  - Computers and Electrical Engineering (COMPELECENG)
  - IET Intelligent Transport Systems (IET ITS)


### ğŸ“« Contact
Email: zhanyangnwpu@gmail.com


### âš¡ Fact
<p align='left'>
  <a href="#"><img src="https://github-readme-stats.vercel.app/api?username=ZhanYang-nwpu&show_icons=true&count_private=true&theme=ambient_gradient" width="450"></a>
</p>



<!--
**ZhanYang-nwpu/ZhanYang-nwpu** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
